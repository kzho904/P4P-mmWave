{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "import os\n",
    "import dataset_utils\n",
    "import NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_and_pad(point_cloud, target_length):\n",
    "    # Flatten the point cloud into a 2D array with X, Y, Z coordinates\n",
    "    # Ensure the data is padded or truncated to match the target length\n",
    "    num_points = len(point_cloud)\n",
    "    padded_point_cloud = np.zeros((target_length, 3))\n",
    "    padded_point_cloud[:num_points] = point_cloud\n",
    "    return padded_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"model_data\"\n",
    "NUM_POINTS = 40\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 32\n",
    "train_points, test_points, train_labels, test_labels, CLASS_MAP = dataset_utils.parse_dataset(NUM_POINTS, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(train_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import data as tf_data\n",
    "import keras\n",
    "import PointNET\n",
    "\n",
    "keras.utils.set_random_seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "dataset = tf_data.Dataset.from_tensor_slices((train_points, train_labels))\n",
    "test_dataset = tf_data.Dataset.from_tensor_slices((test_points, test_labels))\n",
    "train_dataset_size = int(len(dataset) * train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ShuffleDatasetV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} buffer_size must be greater than zero or UNKNOWN_CARDINALITY [Op:ShuffleDatasetV3] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;28mlen\u001b[39m(train_points))\u001b[38;5;241m.\u001b[39mmap(NN\u001b[38;5;241m.\u001b[39maugment)\n\u001b[0;32m      2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;28mlen\u001b[39m(test_points))\u001b[38;5;241m.\u001b[39mbatch(BATCH_SIZE)\n\u001b[0;32m      3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtake(train_dataset_size)\u001b[38;5;241m.\u001b[39mbatch(BATCH_SIZE)\n",
      "File \u001b[1;32mc:\\Users\\Yang Qian\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1501\u001b[0m, in \u001b[0;36mDatasetV2.shuffle\u001b[1;34m(self, buffer_size, seed, reshuffle_each_iteration, name)\u001b[0m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle\u001b[39m(\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28mself\u001b[39m, buffer_size, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reshuffle_each_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetV2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Randomly shuffles the elements of this dataset.\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \n\u001b[0;32m   1415\u001b[0m \u001b[38;5;124;03m  This dataset fills a buffer with `buffer_size` elements, then randomly\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;124;03m    A new `Dataset` with the transformation applied as described above.\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1501\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m shuffle_op\u001b[38;5;241m.\u001b[39m_shuffle(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m       \u001b[38;5;28mself\u001b[39m, buffer_size, seed, reshuffle_each_iteration, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Yang Qian\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\shuffle_op.py:32\u001b[0m, in \u001b[0;36m_shuffle\u001b[1;34m(input_dataset, buffer_size, seed, reshuffle_each_iteration, name)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_shuffle\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     input_dataset,\n\u001b[0;32m     27\u001b[0m     buffer_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     31\u001b[0m ):\n\u001b[1;32m---> 32\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ShuffleDataset(\n\u001b[0;32m     33\u001b[0m       input_dataset, buffer_size, seed, reshuffle_each_iteration, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Yang Qian\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\shuffle_op.py:57\u001b[0m, in \u001b[0;36m_ShuffleDataset.__init__\u001b[1;34m(self, input_dataset, buffer_size, seed, reshuffle_each_iteration, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (tf2\u001b[38;5;241m.\u001b[39menabled() \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     (context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function())):\n\u001b[1;32m---> 57\u001b[0m   variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mshuffle_dataset_v3(\n\u001b[0;32m     58\u001b[0m       input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     59\u001b[0m       buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_size,\n\u001b[0;32m     60\u001b[0m       seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seed,\n\u001b[0;32m     61\u001b[0m       seed2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seed2,\n\u001b[0;32m     62\u001b[0m       seed_generator\u001b[38;5;241m=\u001b[39mgen_dataset_ops\u001b[38;5;241m.\u001b[39mdummy_seed_generator(),\n\u001b[0;32m     63\u001b[0m       reshuffle_each_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reshuffle_each_iteration,\n\u001b[0;32m     64\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m   variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mshuffle_dataset(\n\u001b[0;32m     67\u001b[0m       input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     68\u001b[0m       buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m       reshuffle_each_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reshuffle_each_iteration,\n\u001b[0;32m     72\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[1;32mc:\\Users\\Yang Qian\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:7354\u001b[0m, in \u001b[0;36mshuffle_dataset_v3\u001b[1;34m(input_dataset, buffer_size, seed, seed2, seed_generator, output_types, output_shapes, reshuffle_each_iteration, metadata, name)\u001b[0m\n\u001b[0;32m   7352\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   7353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 7354\u001b[0m   _ops\u001b[38;5;241m.\u001b[39mraise_from_not_ok_status(e, name)\n\u001b[0;32m   7355\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   7356\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yang Qian\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ShuffleDatasetV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} buffer_size must be greater than zero or UNKNOWN_CARDINALITY [Op:ShuffleDatasetV3] name: "
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(len(train_points)).map(NN.augment)\n",
    "test_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)\n",
    "train_dataset = dataset.take(train_dataset_size).batch(BATCH_SIZE)\n",
    "validation_dataset = dataset.skip(train_dataset_size).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(NUM_POINTS, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_structure_1D(input_shape, output_shape):\n",
    "    _model_input = Input(shape=input_shape)\n",
    "    _model = Conv1D(32, kernel_size=1, padding='same', activation='relu')(_model_input)\n",
    "    _model = MaxPooling1D(pool_size=2)(_model)\n",
    "    _model = Flatten()(_model)\n",
    "    _model = Dense(output_shape, activation='softmax')(_model)\n",
    "    model = Model(inputs=_model_input, outputs=_model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Conv3D, MaxPooling3D, Embedding, LSTM, Bidirectional, Reshape, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Example input shape for 3D data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Number of classes or output units\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m model_structure_1D(input_shape, output_shape)\n",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mmodel_structure_1D\u001b[1;34m(input_shape, output_shape)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_structure_1D\u001b[39m(input_shape, output_shape):\n\u001b[0;32m      2\u001b[0m     _model_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[1;32m----> 3\u001b[0m     _model \u001b[38;5;241m=\u001b[39m Conv1D(\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(_model_input)\n\u001b[0;32m      4\u001b[0m     _model \u001b[38;5;241m=\u001b[39m MaxPooling1D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)(_model)\n\u001b[0;32m      5\u001b[0m     _model \u001b[38;5;241m=\u001b[39m Flatten()(_model)\n",
      "File \u001b[1;32mc:\\Users\\Yang Qian\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1026\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1019\u001b[0m eager \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[0;32m   1021\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1022\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m   1023\u001b[0m     build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m eager,\n\u001b[0;32m   1024\u001b[0m     training\u001b[38;5;241m=\u001b[39mtraining_mode):\n\u001b[1;32m-> 1026\u001b[0m   input_spec\u001b[38;5;241m.\u001b[39massert_input_compatibility(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec, inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1027\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m eager:\n\u001b[0;32m   1028\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n",
      "File \u001b[1;32mc:\\Users\\Yang Qian\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:226\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(input_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    222\u001b[0m                      layer_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    223\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected max_ndim=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(spec\u001b[38;5;241m.\u001b[39mmax_ndim) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    224\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(ndim))\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmin_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 226\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m    227\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(input_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    229\u001b[0m                      layer_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    230\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: expected min_ndim=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(spec\u001b[38;5;241m.\u001b[39mmin_ndim) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    231\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(ndim) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    232\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Full shape received: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    233\u001b[0m                      \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(shape)))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'rank'"
     ]
    }
   ],
   "source": [
    "input_shape = (40, 5)  # Example input shape for 3D data\n",
    "output_shape = 3  # Number of classes or output units\n",
    "model = model_structure_1D(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the input shape (5 features)\n",
    "input_shape = (None, 5)\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential()\n",
    "\n",
    "# 1. CNN layer\n",
    "model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "# 2. LSTM layer\n",
    "model.add(layers.LSTM(50, return_sequences=True))\n",
    "model.add(layers.LSTM(50))\n",
    "\n",
    "# 3. Dense layers\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='linear'))  # Output layer (you can adjust the output size and activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)       │        \u001b[38;5;34m23,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m2,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,825</span> (182.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,825\u001b[0m (182.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,825</span> (182.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,825\u001b[0m (182.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "history = model.fit(train_points, train_labels, epochs=100, batch_size=32, validation_data=(test_points, test_labels), verbose=4)\n",
    "test_loss, test_acc = model.evaluate(test_points, test_labels, verbose=2)\n",
    "\n",
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
