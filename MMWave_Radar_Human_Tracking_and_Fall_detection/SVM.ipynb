{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_utils\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_background_subtraction(current_frame_data):\n",
    "    filtered_data = []\n",
    "    for point in current_frame_data:\n",
    "        filtered_data.append(point)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(num_points, DATA_DIR):\n",
    "    train_points = []\n",
    "    train_labels = []\n",
    "    test_points = []\n",
    "    test_labels = []\n",
    "    class_map = {}\n",
    "    folders = glob(os.path.join(DATA_DIR, \"[!README]*\"))\n",
    "\n",
    "    for i, folder in enumerate(folders):\n",
    "        print(\"processing class: {}\".format(os.path.basename(folder)))\n",
    "        # store folder name with ID so we can retrieve later\n",
    "        class_map[i] = folder.split(\"/\")[-1]\n",
    "        # gather all files\n",
    "        train_files = glob(os.path.join(folder, \"train/*\"))\n",
    "        test_files = glob(os.path.join(folder, \"test/*\"))\n",
    "\n",
    "        for f in train_files:\n",
    "            train_points_sample = []\n",
    "            with open(f, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "                for arr in data:\n",
    "                    bg_rm_arr = no_background_subtraction(arr)\n",
    "                    #bg_rm_arr = background_subtraction(background_data, arr)\n",
    "                    train_points_sample.append(bg_rm_arr)\n",
    "                train_points_sample = np.array(train_points_sample).reshape(-1,5).astype(np.float16)\n",
    "                train_points.append(train_points_sample)\n",
    "                train_labels.append(i)\n",
    "               \n",
    "        \n",
    "        for f in test_files:\n",
    "            test_points_sample = []\n",
    "            with open(f, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "                for arr in data:\n",
    "                    bg_rm_arr = no_background_subtraction(arr)\n",
    "                    #bg_rm_arr = background_subtraction(background_data, arr)\n",
    "                    test_points_sample.append(bg_rm_arr)\n",
    "                test_points_sample = np.array(test_points_sample).reshape(-1,5).astype(np.float16)\n",
    "                test_points.append(test_points_sample)\n",
    "                test_labels.append(i)\n",
    "    return (\n",
    "        np.array(train_points),\n",
    "        np.array(test_points),\n",
    "        np.array(train_labels),\n",
    "        np.array(test_labels),\n",
    "        class_map,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
